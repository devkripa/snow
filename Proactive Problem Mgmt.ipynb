{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "# import os\n",
    "# import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_url = (\"/Users/devkrroy/Dev/Projects/snow/data/export3.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(target_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Number' 'Assignment_group' 'Priority' 'State' 'Category' 'Subcategory'\n",
      " 'Severity' 'Closure_CI' 'Location' 'Close_code' 'Configuration_item'\n",
      " 'Child_Incidents' 'Contact_type' 'Duration' 'Impact' 'Short_description'\n",
      " 'Created' 'dates' 'date' 'day' 'month' 'dom' 'week' 'week2' 'cluster'\n",
      " 'cluster1' 'cluster_name1' 'cluster_name']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Number', 'Assignment_group', 'Priority', 'State', 'Category',\n",
    "       'Subcategory', 'Severity', 'Closure_CI', 'Location', 'Close_code',\n",
    "       'Configuration_item', 'Child_Incidents', 'Contact_type',\n",
    "       'Duration', 'Impact', 'Short_description', 'Created']\n",
    "df = df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input file (95373, 17)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of input file\", df.shape)\n",
    "# df = df.head(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out some categories with instances < 50 for now , remove this filter in future\n",
    "# df = df.groupby(\"Category\").filter(lambda x: len(x) > 50)\n",
    "# df = df.reset_index(drop =True)\n",
    "# df.Category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk text preprocessing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import contractions\n",
    "\n",
    "from sklearn import feature_extraction\n",
    "# from nltk.tag import pos_tag\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "lemmer=WordNetLemmatizer()\n",
    "\n",
    "#extend stop words\n",
    "new_stopwords = ['chw','edu','phx','vapp']\n",
    "stop.extend(new_stopwords)\n",
    "\n",
    "# to be tried - apply text collocations\n",
    "\n",
    "def pre_process(text):\n",
    "        \n",
    "    # try to capture the IPs    \n",
    "    ip_pattern = re.compile(r'([A-Za-z0-9]{2,}[-.]{1,1}){2,6}([A-Za-z0-9]*)')   \n",
    "    ip = text.apply(lambda x: ' '.join(word for word in re.split('[\\': (),]', x) if ip_pattern.match(word)))\n",
    "    \n",
    "    text = text.apply(lambda x: ' '.join(word.lower() for word in x.split()))  # lower case\n",
    "#   text = text.apply(lambda x: ' '.join(contractions.fix(word) for word in x.split()))  # replace contractions\n",
    "\n",
    "    text = text.str.replace('[^A-Za-z ]', ' ')  # remove non words\n",
    "    \n",
    "    text = text.apply(lambda x: ' '.join([word for word in x.split() if word not in set(stop)]))   #stop\n",
    "    text = text.apply(lambda x: ' '.join([lemmer.lemmatize(word, pos='v') for word in x.split()]))       #lemma\n",
    "    text = text.apply(lambda x: ' '.join([word for word in x.split() if len(word) > 1 ]))  #length >1\n",
    "\n",
    "    return (text, ip)\n",
    "    \n",
    "normalized = pre_process(df['Short_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 119470 samples and 736994 outcomes>\n"
     ]
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokenized_word=word_tokenize(normalized[0].to_string())\n",
    "\n",
    "fdist = FreqDist(tokenized_word)\n",
    "print(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('...', 43458),\n",
       " ('issue', 18550),\n",
       " ('unable', 16168),\n",
       " ('network', 13663),\n",
       " ('login', 12342),\n",
       " ('id', 11318),\n",
       " ('account', 10722),\n",
       " ('user', 10677),\n",
       " ('utilization', 9289),\n",
       " ('lock', 6667),\n",
       " ('set', 6318),\n",
       " ('desktop', 6288),\n",
       " ('threshold', 6064),\n",
       " ('nmscust', 5907),\n",
       " ('password', 5889),\n",
       " ('cerner', 5699),\n",
       " ('need', 5684),\n",
       " ('printer', 5671),\n",
       " ('mdf', 5595),\n",
       " ('reset', 5240),\n",
       " ('monitor', 4601),\n",
       " ('phone', 4516),\n",
       " ('device', 4365),\n",
       " ('cpu', 4228),\n",
       " ('able', 4222),\n",
       " ('ms', 4202),\n",
       " ('main', 4135),\n",
       " ('keyboard', 4045),\n",
       " ('pc', 4031),\n",
       " ('dev', 3647),\n",
       " ('application', 3633),\n",
       " ('ap', 3630),\n",
       " ('username', 3185),\n",
       " ('computer', 3170),\n",
       " ('helpdesk', 3005),\n",
       " ('zother', 2973),\n",
       " ('access', 2659),\n",
       " ('file', 2642),\n",
       " ('error', 2631),\n",
       " ('rt', 2577),\n",
       " ('mouse', 2505),\n",
       " ('work', 2485),\n",
       " ('wc', 2401),\n",
       " ('up', 2392),\n",
       " ('smart', 2364),\n",
       " ('rid', 2353),\n",
       " ('duo', 2258),\n",
       " ('kyocera', 2244),\n",
       " ('job', 2196),\n",
       " ('xl', 2182)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Terms'] = normalized[0]\n",
    "df['IPs'] = normalized[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    phx-vapp-689.chw.edu\n",
       "1                        \n",
       "2            PHX-VAPP-408\n",
       "3                        \n",
       "4                        \n",
       "5                        \n",
       "6                        \n",
       "7           10.203.212.24\n",
       "8    phx-vapp-842.chw.edu\n",
       "9                        \n",
       "Name: IPs, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['IPs'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# print(re.split('[:\\' ]', '\\'phx-vapp-689.chw.edu\\': Utilization is \\'85.2\\'. Threshold is set to \\'Disk/File System/{C}/percent full >= 85\\''))\n",
    "\n",
    "# ci_pattern = re.compile(r'([A-Za-z0-9]{2,}[-.]{1,1}){2,6}([A-Za-z0-9]*)')\n",
    "\n",
    "# print(ci_pattern.match('phx-vapp-238.chw.edu'))\n",
    "# print(ci_pattern.match('CPU Utilization is '))\n",
    "# print(ci_pattern.match('85.2'))\n",
    "# print(ci_pattern.match('10.250.243.2'))\n",
    "# print(ci_pattern.match('192.168.2.85)'))\n",
    "# test = pd.DataFrame({'strings': ['...', 'a(b$c']})\n",
    "# test.strings.str.replace('[^a-zA-Z ]', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a tokenizer which returns the set of tokens in the text that it is passed\n",
    "\n",
    "def tokenize_only(text):\n",
    "    # tokenize by  word \n",
    "    tokens = [word.lower() for word in nltk.word_tokenize(text) ]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.3 s, sys: 89.6 ms, total: 13.4 s\n",
      "Wall time: 13.4 s\n",
      "(95373, 3737)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer( max_features=10000, max_df=0.8, min_df=0.0005,                                  \n",
    "                                  use_idf=True, tokenizer=word_tokenize, ngram_range=(1,3))\n",
    "\n",
    "%time tfidf_matrix = tfidf_vectorizer.fit_transform(df['Terms'].values.astype('U'))\n",
    "\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['activate issue', 'activate issue resolve', 'activation', 'activation code', 'activation link', 'activation link user', 'active', 'active job', 'active job complete', 'ad', 'adapter', 'add', 'add printer', 'additional', 'additional info', 'additional info time', 'address', 'ade', 'adg', 'adg pck', 'adg pck bla', 'adg rid', 'adg rid bla', 'adg wealthpoint', 'adg wealthpoint ontime', 'adh', 'admin', 'admin access', 'admin mdf', 'admin mdf main', 'admin right', 'admin right need', 'administration', 'administration run', 'admit', 'admit loc', 'adobe', 'adt', 'adt allergy', 'adt issue', 'adt nitiate', 'adt nitiate identity', 'adt order', 'adt source', 'adt source ini', 'adt st', 'agch', 'agency', 'agency tier', 'agency tier mft', 'agent', 'agent run', 'agg', 'agg mdf', 'agg mdf dt', 'agg mdf main', 'agg mdf sjpvh', 'alarm', 'alarm js', 'alarm js nberrorcond', 'alarm nberrorcond', 'alarm qs', 'alarm qs nberrorcond', 'alert', 'alert dhi', 'alert dhi ssrm', 'alert high', 'alive', 'alive error', 'alive error throw', 'allergy', 'allocate', 'allocate record', 'allocate record file', 'allow', 'allscripts', 'allscripts account', 'allscripts ambulatory', 'allscripts ehr', 'allscripts ehr ambulatory', 'allscripts unable', 'allscripts unable login', 'already', 'already do', 'already do user', 'also', 'alt', 'ambulatory', 'ambulatory allscripts', 'ambulatory allscripts ambulatory', 'amcore', 'amcore date', 'analytics', 'anyconnect', 'anyconnect issue', 'anyconnect vpn', 'anyconnect vpn cisco', 'anything', 'ap', 'ap ap']\n"
     ]
    }
   ],
   "source": [
    "terms = tfidf_vectorizer.get_feature_names()\n",
    "print(terms[100:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.06 s, sys: 3.93 ms, total: 1.07 s\n",
      "Wall time: 1.07 s\n"
     ]
    }
   ],
   "source": [
    "# Mini Batch K means\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "num_clusters = 30\n",
    "km = MiniBatchKMeans(n_clusters = num_clusters, init = 'k-means++', n_init = 3, init_size = 300, batch_size = 100, random_state = 1)\n",
    "%time km.fit(tfidf_matrix)\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cluster in pickle file for future use\n",
    "# import pickle\n",
    "\n",
    "# pickle.dump(km, open('pkl/km_1.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: lock user, account lock user, lock user id, account, lock, account lock, user, user id, network account, network account lock, network, id, unlock account, unlock, account issue, unlock account issue, issue, issue resolve, resolve, account issue resolve,\n",
      "Cluster 1: threshold set disk, disk file, set disk, set disk file, disk file system, percent full, file system, disk, percent, full, system, file system percent, system percent, system percent full, file, utilization threshold set, threshold set, utilization threshold, utilization, set,\n",
      "Cluster 2: login, unable login, unable, login username, unable login username, username, network, network unable, network unable login, account, account unable, network account unable, account unable login, do, encryption unable login, encryption, encryption unable, password, network account, unable login uid,\n",
      "Cluster 3: utilization, threshold set utilization, set utilization, cpu utilization threshold, cpu utilization, cpu, utilization threshold, utilization threshold set, threshold set, set, threshold, viis cpu utilization, viis cpu, viis, chwemadm cpu, chwemadm cpu utilization, chwemadm, medbg cpu, medbg cpu utilization, medbg,\n",
      "Cluster 4: application issue, application, issue, zother, helpdesk, issue helpdesk, laptop computer, desktop laptop computer, desktop laptop, laptop computer issue, computer issue, application issue helpdesk, clinical application issue, clinical application, laptop, clinical, business application issue, business application, business, computer,\n",
      "Cluster 5: packet good percentage, info time, good percentage, good percentage see, ping packet good, ping packet, additional info, additional info time, see additional info, percentage see additional, see additional, percentage see, packet good, percentage, packet, additional, ping, info, good, see,\n",
      "Cluster 6: smart up, up, smart, nberrorcond, xl, up rt, smart up rt, rt xl, up rt xl, rt, qs nberrorcond, qs, device alarm, alarm, communication lose link, lose link, lose link status, communication lose, device alarm qs, alarm qs nberrorcond,\n",
      "Cluster 7: able login, able, login, password, reset, login issue, account, do, able login issue, resolve, password reset, network, login issue resolve, issue resolve, userid, issue, hduv do, hduv, user, login need,\n",
      "Cluster 8: network password, network password reset, password reset, reset, password, network, ms password reset, ms password, ms, reset unable login, password reset unable, reset unable, password reset username, reset username, login, username, unable login, unable, reset user id, password reset user,\n",
      "Cluster 9: ms password reset, ms password, ms, password reset, reset, password, password reset username, reset username, username, break, work, phone, reset user id, password reset user, reset user, user id, user, id, fy, full error event,\n",
      "Cluster 10: workstation wheel, wow workstation wheel, wow workstation, wheel, workstation, wow, workstation wheel wow, wheel wow, wheel wow workstation, workstation wheel issue, wheel issue, issue, round, scanner, net, pod, setup, first, scan, scanner work,\n",
      "Cluster 11: network account lock, account lock, lock, network account, account, network, account lock username, lock username, account lock unable, username, lock unable, lock unable login, unable login, login, unable, account lock userid, lock userid, userid, unlock, account lock user,\n",
      "Cluster 12: notification text, date, text, notification, amcore, amcore date, notification text amcore, text amcore, text amcore date, phxlits, verification, crhcem, workstation, machine, send, resolve, radiology, update, room, close,\n",
      "Cluster 13: utilization, vprt cpu utilization, vprt cpu, vprt, cpu utilization threshold, threshold set utilization, set utilization, cpu utilization, cpu, utilization threshold set, threshold set, utilization threshold, set, threshold, sjw vprt cpu, sjw vprt, sjw, mgh, seq, mmc,\n",
      "Cluster 14: cerner, issue, powerchart, cerner powerchart, cerner physician, physician, cerner physician issue, physician issue, firstnet, cerner firstnet, cerner lab, unable, lab, order, issue cerner, physician issue cerner, issue cerner physician, patient, launch, schedule,\n",
      "Cluster 15: mrmc, ap, main mrmc, mdf, ap mdf, wc mdf main, ap associate controller, associate controller, ap associate, associate, controller, wc mdf, nmscust wc mdf, mdf main, nmscust wc, wc, main, nmscust, pt, ap mdf main,\n",
      "Cluster 16: desktop issue, desktop, desktop issue desktop, issue desktop issue, issue desktop, issue, scanner, room, id, turn, icon, dev id, slow, dev, windows, work, screen, look, myjourney, team,\n",
      "Cluster 17: cookies, desktop work, cache, clear, slow, reboot, ip, work, dev id, dev, issue resolve, desktop, resolve, id, issue, full error, ge, frequently, gecb application issue, gecb application,\n",
      "Cluster 18: login user, login user id, unable login user, user id, user, login, unable login, id, unable, account, network, network account, able login user, account unable login, account unable, customer unable login, customer, customer unable, account customer unable, account customer,\n",
      "Cluster 19: ap, mdf, wc mdf, nmscust wc mdf, nmscust wc, wc, associate controller, ap associate controller, ap associate, associate, controller, nmscust, wc mdf main, main, mdf main, ap mdf, dhmf, bmh, bmh ap, dhmf ap,\n",
      "Cluster 20: keyboard mouse, mouse, keyboard, pc monitor keyboard, monitor keyboard mouse, monitor keyboard, pc monitor, pc, monitor, keyboard mouse issue, mouse issue, mouse pc, keyboard mouse pc, mouse pc monitor, issue, mouse keyboard mouse, keyboard mouse keyboard, mouse keyboard, rm, room,\n",
      "Cluster 21: unable, id, need, error, work, device, user, issue, ms, access, dev, dev id, device id, computer, duo, outlook, application, desktop, call, phxasp,\n",
      "Cluster 22: phone, phone phone issue, phone phone, phone issue, issue, phone work, replace, nurse, work, hold, need replace, fix, add, line, ext, test, need, suite, link, enable,\n",
      "Cluster 23: database, backup overdue, overdue, backup, fingerprint database, fingerprint, database backup overdue, database backup, fingerprint database backup, database log, database log backup, log backup overdue, log backup, log, fingerprint database log, store database, vault store database, vault store, store, vault,\n",
      "Cluster 24: user, resolve, issue, issue resolve, id, user id, password, take, remote, take remote, reset, need, unable, dev, user name, name, network, access, account, dev id,\n",
      "Cluster 25: utilization, set utilization, threshold set utilization, cpu utilization threshold, cpu utilization, cpu, utilization threshold set, threshold set, utilization threshold, set, threshold, phxpvapp, vsql, bmh, snmh, sm, phxpvsdm, sql, phxpcxn, vctx,\n",
      "Cluster 26: peer, nmscust, syslog critical, syslog, critical, bgp peer, bgp, mdf, peer bgp, peer bgp peer, establish, bgp peer establish, peer establish, cr, nmscust cr, main, cr mdf, nmscust cr mdf, mdf main, cr mdf main,\n",
      "Cluster 27: ii, ii user, ii user id, ii issue resolve, ii issue, id, user id, issue resolve, resolve, user, password reset ii, reset ii, ii dev, reset ii user, lock ii, ii unable, account lock ii, ii dev id, issue, lock ii user,\n",
      "Cluster 28: active job complete, complete exit, complete exit status, job complete, job complete exit, active job, exit status, exit, active, complete, job, status, ge, ge centricity, fy, gecb, gecb able, gal, ge centricity business, full warn event,\n",
      "Cluster 29: printer, printer issue, kyocera, kyocera printer, kyocera printer issue, issue, printer issue kyocera, issue kyocera, issue kyocera printer, general printer issue, general printer, general, print, label, label printer, label printer issue, printer unable, id, map, printer unable print,\n",
      "(30, 2)\n"
     ]
    }
   ],
   "source": [
    "# Create mapping of ngram features into clusters, \n",
    "# save into terms map object with key as cluster name (first feature in each cluster)\n",
    "# terms = top 20 ngram features\n",
    "\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = tfidf_vectorizer.get_feature_names()\n",
    "terms_map = pd.DataFrame(index=np.arange(0, num_clusters),columns=['terms','key'])    \n",
    "for i in range(num_clusters):\n",
    "    print(\"Cluster %d:\" % i, end='')\n",
    "    #terms_map['key'] = i\n",
    "    list = [] \n",
    "    for ind in order_centroids[i, :20]:\n",
    "        print(' %s' % terms[ind], end=',')\n",
    "        list.append(terms[ind])\n",
    "    for ind2 in order_centroids[i, :1]:\n",
    "        terms_map.key.loc[i] = terms[ind2]\n",
    "\n",
    "    str = ', '.join(list) \n",
    "    terms_map.terms.loc[i] = str\n",
    "    print()\n",
    "print(terms_map.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
